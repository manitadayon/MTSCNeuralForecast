{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright  (c) 2021  California  Institute  of Technology (\"Caltech\"). U.S. Government sponsorship acknowledged.\n",
    " \n",
    " All  rights  reserved.\n",
    " \n",
    " Redistribution  and  use  in  source  and  binary  forms,  with  or  without  modification,  are  permitted  provided that the  following  conditions are  met:\n",
    " \n",
    " - Redistributions  of  source  code  must  retain  the  above  copyright  notice,  this  list  of  conditions  and the  following  disclaimer.\n",
    " - Redistributions  in  binary  form  must  reproduce  the  above  copyright  notice,  this  list  of  conditions and  the  following  disclaimer  in  the  documentation  and/or other materials provided  with  the distribution.\n",
    " - Neither  the  name  of  Caltech  nor  its  operating  division,  the  Jet  Propulsion  Laboratory,  nor  the names  of  its  contributors  may  be  used  to  endorse  or  promote  products  derived  from  this  software without  specific  prior  written  permission.\n",
    " \n",
    " THIS  SOFTWARE  IS  PROVIDED  BY  THE  COPYRIGHT  HOLDERS  AND  CONTRIBUTORS  \"AS IS\" AND  ANY  EXPRESS  OR  IMPLIED  WARRANTIES, INCLUDING, BUT  NOT  LIMITED  TO, THE  IMPLIED  WARRANTIES  OF  MERCHANTABILITY  AND  FITNESS  FOR A  PARTICULAR PURPOSE ARE DISCLAIMED. \n",
    " IN NO EVENT SHALL THE  COPYRIGHT  OWNER OR CONTRIBUTORS BE  LIABLE  FOR  ANY  DIRECT,  INDIRECT,  INCIDENTAL,  SPECIAL, EXEMPLARY, OR  CONSEQUENTIAL  DAMAGES (INCLUDING,  BUT  NOT  LIMITED  TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS  OF  USE, DATA, OR  PROFITS; OR  BUSINESS  INTERRUPTION)  HOWEVER  CAUSED  AND  ON  ANY  THEORY  OF  LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,  OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)  ARISING  IN  ANY  WAY  OUT  OF  THE  USE  OF  THIS  SOFTWARE,  EVEN  IF ADVISED OF  THE  POSSIBILITY  OF  SUCH  DAMAGE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the script for feature based clustering corresponding to method B in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, select_features\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Path=sorted(glob.glob('/Desktop/*.csv'))\n",
    "All_Path.sort(key=os.path.getmtime)\n",
    "All_Path=[ii.split('/')[-1].split('.')[0] for ii in All_Path]\n",
    "DATA=All_Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat=1  \n",
    "num_feature_per_column = 794   ## The number of features extracted by tsfresh per each time series\n",
    "Feat_matrix2=np.zeros([len(DATA),num_feature_per_column*num_feat])   \n",
    "cwd=os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is for selected number of columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpath='/Desktop/'\n",
    "START=time.time()\n",
    "for ii in range(Feat_matrix2.shape[0]):\n",
    "    DATA1_name=subpath+DATA[ii]+'.csv'\n",
    "    DATA1=pd.read_csv(DATA1_name)\n",
    "    DATA2=pd.DataFrame()\n",
    "    DATA2=pd.DataFrame(np.zeros((DATA1.shape[0],num_feat)))\n",
    "   \n",
    "    DATA2['Time']=DATA1['Time'].values\n",
    "    scaler =  preprocessing.MinMaxScaler()\n",
    "    DATA2.iloc[:,0:num_feat] = scaler.fit_transform(DATA1.iloc[:,3].values.reshape((-1,1)))\n",
    "    DATA2['id']=ii\n",
    "    extracted_features = extract_features(DATA2, column_id='id',column_sort=\"Time\",disable_progressbar=True)\n",
    "    Feat_matrix2[ii,:]=extracted_features\n",
    "    print(ii)\n",
    "END=time.time()   \n",
    "print(\"Time takes is\", END-START)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is for all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpath='/Desktop/'\n",
    "START=time.time()\n",
    "for ii in range(Feat_matrix2.shape[0]):\n",
    "    DATA1_name=subpath+DATA[ii]+'.csv'\n",
    "    DATA1=pd.read_csv(DATA1_name)\n",
    "    scaler =  preprocessing.MinMaxScaler()\n",
    "    DATA1.iloc[:,1:4] = scaler.fit_transform(DATA1.iloc[:,1:4])\n",
    "    DATA1['id']=ii\n",
    "    extracted_features = extract_features(DATA1, column_id='id',column_sort=\"Time\",disable_progressbar=True) # Time was Time_stamp for Chevron Project\n",
    "    Feat_matrix2[ii,:]=extracted_features\n",
    "    print(ii)\n",
    "END=time.time()   \n",
    "print(\"Time takes is\", END-START)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the NaN and Remove it.\n",
    "### Feat_matrix2 is the feature matrix after normalizing the features\n",
    "### Feat_matrix is the   feature matrix before normalizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can do anything you like with Nan such as mean, median, KNN and etc.\n",
    "A=(np.where(np.isnan(Feat_matrix2)))\n",
    "print(len(A[0])) # Number of NaN\n",
    "print(Feat_matrix2.shape[0]*Feat_matrix2.shape[1])  # Total number of entries \n",
    "print(len(A[0])/(Feat_matrix2.shape[0]*Feat_matrix2.shape[1]))  # Ratio of NaN entries\n",
    "Feat_matrix2_new=np.nan_to_num(Feat_matrix2)    # Replace NaN with zero and infinity with finite number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =  preprocessing.MinMaxScaler()\n",
    "Feat_matrix_new2 = scaler.fit_transform(Feat_matrix2_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Kmeans and Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for ii in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=ii, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(Feat_matrix_new2)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Silhouette Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(2, 11):\n",
    "    clusterer = KMeans(n_clusters=ii, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    preds = clusterer.fit_predict(Feat_matrix_new2)\n",
    "    score = silhouette_score (Feat_matrix_new2, preds, metric='euclidean')\n",
    "    print (\"For n_clusters = {}, silhouette score is {}\".format(ii, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=40, random_state=0)\n",
    "pred_y = kmeans.fit_predict(Feat_matrix_new2)\n",
    "pred_y=[ii+1 for ii in pred_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "pc= pca.fit_transform(Feat_matrix_new2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(pc, method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')  \n",
    "Label=cluster.fit_predict(pc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
